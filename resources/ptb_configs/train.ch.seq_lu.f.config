### use # to comment out the configure item
### I/O ###

train_dir=../sample_data/cp_datasets/ptb/ptb-train.seq_lu
dev_dir=../sample_data/cp_datasets/ptb/ptb-dev.seq_lu
test_dir=../sample_data/cp_datasets/ptb/ptb-dev.seq_lu

model_dir=../parsing_models/ptb.emnlp2018.f
word_emb_dir=../resources/glove.6B.100d.txt


#raw_dir=
#decode_dir=
#dset_dir=
#load_model_dir=
#char_emb_dir=


norm_word_emb=False
norm_char_emb=False
number_normalized=False
seg=False
word_emb_dim=100
char_emb_dim=30

###NetworkConfiguration###
use_crf=False
use_char=True
word_seq_feature=LSTM
char_seq_feature=LSTM
feature=[POS] emb_size=20


###TrainingSetting###
status=train
optimizer=SGD
iteration=100
batch_size=8
ave_batch_loss=True

###Hyperparameters###
cnn_layer=4
char_hidden_dim=50
hidden_dim=800
dropout=0.5
lstm_layer=2
bilstm=True
learning_rate=0.02
lr_decay=0.05
momentum=0.9
l2=0
gpu=False
#clip=
main_tasks=1
tasks=1
tasks_weights=1
optimize_with_evalb=True


###PathsToAdditionalScripts###
tree2labels=tree2labels
en2mt=tree2labels/encoding2multitask.py
evaluate=tree2labels/evaluate.py
evalb=tree2labels/EVALB/evalb
gold_dev_trees=../sample_data/cp_datasets/PTB_pred_tags/dev.trees





